# ğŸ« Support Ticket Analytics Platform

[![CI/CD Pipeline](https://github.com/Youssef-Fawel/support-ticket-analytics-platform/actions/workflows/ci.yml/badge.svg)](https://github.com/Youssef-Fawel/support-ticket-analytics-platform/actions/workflows/ci.yml)
[![Tests](https://img.shields.io/badge/tests-35%2F35_passing-success)](https://github.com/Youssef-Fawel/support-ticket-analytics-platform)
[![Python](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green)](https://fastapi.tiangolo.com/)
[![MongoDB](https://img.shields.io/badge/MongoDB-6.0-brightgreen)](https://www.mongodb.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

> **Production-ready multi-tenant SaaS backend for support ticket management, classification, and real-time analytics**

A highly scalable, fault-tolerant system built with FastAPI and MongoDB, featuring advanced patterns like Circuit Breakers, Distributed Locks, Rate Limiting, and comprehensive audit logging.

---

## ğŸŒŸ Key Features

### Core Functionality
- ğŸ”„ **Automated Ticket Ingestion** - Paginated data fetching with idempotency guarantees
- ğŸ·ï¸ **Intelligent Classification** - Rule-based urgency, sentiment, and action detection
- ğŸ“Š **Real-time Analytics** - Sub-500ms query performance for 10,000+ tickets
- ğŸ”” **Reliable Notifications** - Retry logic with exponential backoff (no external libraries)
- ğŸ’¾ **Optimized Storage** - MongoDB indexes for high-performance queries
- ğŸ¥ **Health Monitoring** - Dependency checks and system status reporting

### Advanced Patterns
- âš¡ **Circuit Breaker** - Fault tolerance for external service calls
- ğŸ”’ **Distributed Locks** - MongoDB-based locking (no Redis required)
- ğŸš¦ **Rate Limiting** - Global 60 req/min throttling across tenants
- ğŸ“ **Audit Logging** - Complete traceability of all operations
- ğŸ”„ **Change Detection** - Incremental sync with field-level history
- ğŸ‘¥ **Multi-tenant Isolation** - Strict data separation

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI App   â”‚
â”‚   (Async/Await) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º Ingestion Service â”€â”€â–º External API (paginated)
         â”‚                â”‚
         â”‚                â”œâ”€â–º Rate Limiter (60/min)
         â”‚                â””â”€â–º Circuit Breaker (5/10 failures)
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º Classification Service â”€â”€â–º Rule Engine
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º Analytics Service â”€â”€â–º MongoDB Aggregation
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º Notification Service â”€â”€â–º Retry Logic (3 attempts)
         â”‚
         â””â”€â”€â”€â”€â”€â–º Lock Service â”€â”€â–º MongoDB Atomic Ops
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                    â”‚ MongoDB â”‚
                    â”‚  6.0    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ Design Constraints

This system was built under strict production-ready constraints:

1.  **No External Retry Libraries** - Manual implementation using `asyncio`
2.  **Database-Centric Analytics** - MongoDB aggregation pipeline (not Python loops)
3.  **Manual Pagination Control** - Explicit page handling without client helpers
4.  **No Distributed Lock Libraries** - MongoDB atomic operations only

---

## ğŸ“‹ Requirements

1.  **No External Retry Libraries**  
    Do NOT use `tenacity`, `backoff`, or any other retry library. Implement retry behaviour yourself using Python's standard `asyncio` primitives.

2.  **Databaseâ€‘Centric Analytics**  
    The `/stats` endpoint must compute its metrics **inside MongoDB** (or within the database layer), not in Python loops over large result sets.
    - It should comfortably handle **10,000+ tickets** without breaching a roughly **2â€‘second** response budget in the provided `docker-compose` setup.
    - Solutions that repeatedly load full collections into memory or iterate over every document in Python will be treated as failing this requirement, even if they "work" on small data.

3.  **Manual Pagination**  
    You are expected to control pagination from your own code (looping over pages, handling termination, etc.). Avoid highâ€‘level client helpers that hide pagination logic.

4.  **No External Distributed Lock Libraries**  
    Do NOT use libraries such as `redis-lock`, `pottery`, or `sherlock`. Implement your own lock mechanism using MongoDB's atomic operations (for example, `findOneAndUpdate`).

---

## Requirements (All Tasks are Mandatory)

### Task 1: Reliable Data Ingestion
- Implement `POST /ingest/run?tenant_id=...` to fetch tickets from the Mock External API.
- Ensure the system fetches all available data from the paginated external source.
- The ingestion process must be idempotent. Re-running ingestion for the same tenant should not result in duplicate records.

### Task 2: Classification Logic
Implement rule-based classification in `ClassifyService`:
- Determine **Urgency** (high/medium/low), **Sentiment** (negative/neutral/positive), and **Requires Action** (boolean).
- Use keywords such as "refund", "lawsuit", "urgent", "angry", "broken", "GDPR" to determine these values.

### Task 3: Advanced Analytics & Reporting
Design `GET /tenants/{tenant_id}/stats` so that it can be used to power a tenantâ€‘level analytics dashboard.
- At a minimum, include: `total_tickets`, `by_status` (counts), `urgency_high_ratio`, and an `hourly_trend` of ticket creation over the last 24 hours.
- You should rely on MongoDB's aggregation capabilities (or equivalent DBâ€‘side operators) rather than adâ€‘hoc Python postâ€‘processing.
- Optionally, you may add richer analytics such as `top_keywords` or `at_risk_customers`.

### Task 4: Reliable Alerting & Retries
- When a ticket is classified as high priority, call the notification service: `POST http://mock-external-api:9000/notify`.
- The notification service is intentionally unstable (it may return 5xx responses or be slow). You are responsible for ensuring that high-priority notifications are successfully delivered without blocking the main ingestion flow.
- Implement a robust handling strategy that accounts for transient failures and maintains system availability.

### Task 5: System Health Monitoring
- Implement `GET /health` to report the status of the system and its critical dependencies. Return a non-200 status if any dependency is unavailable.

### Task 6: Ingestion Audit Logging
- Record the history of every ingestion run in an `ingestion_logs` collection.
- Logs must include timestamps, final status, and processing metrics. Traceability must be maintained even if the process fails.

### Task 7: Resource Management & Stability
- Ensure that your database connection handling and resource usage remain stable under sustained load (e.g., during high-volume ingestion and simultaneous analytics requests).
- The system should exhibit production-ready behavior, avoiding common pitfalls related to connection lifecycle and resource exhaustion.

### Task 8: Concurrent Ingestion Control
- Prevent concurrent `POST /ingest/run` executions for the same tenant.
- If an ingestion job is already running for a tenant, return **409 Conflict**.
- Implement a lock mechanism using MongoDB atomic operations (e.g., `findOneAndUpdate`), and ensure locks expire automatically if they are not refreshed within approximately **60 seconds**.
- Provide an ingestion status endpoint: `GET /ingest/status?tenant_id=...`.

### Task 9: Ingestion Job Management
- When ingestion starts, generate a `job_id` and include it in the response.
- Implement `GET /ingest/progress/{job_id}` to report job status and progress (e.g., `{"job_id": "...", "status": "running", "progress": 45, "total_pages": 100, "processed_pages": 45}`).
- Implement `DELETE /ingest/{job_id}` to allow graceful cancellation of a running job. Preserve already-ingested data and record the final job status (e.g., `cancelled`).

### Task 10: External Rate Limiting
- The Mock External API is limited to **60 calls per minute** and will return `429 Too Many Requests` with a `Retry-After` header if the limit is exceeded.
- Implement global rate limiting so that total outbound calls stay within this limit, even when multiple tenants are ingesting in parallel.
- On `429` responses, wait for the `Retry-After` duration before retrying.
- You may implement any algorithm (e.g., token bucket, sliding window) and may use external **rate limiting** libraries.

### Task 11: Circuit Breaker for Notifications
- Implement a Circuit Breaker for the notification endpoint `POST http://mock-external-api:9000/notify`.
- Apply the following state transitions:
  - CLOSED â†’ OPEN: at least 5 failures in the last 10 requests.
  - OPEN â†’ HALF_OPEN: after approximately 30 seconds.
  - HALF_OPEN â†’ CLOSED: 1 successful request.
  - HALF_OPEN â†’ OPEN: 1 failed request.
- While in the OPEN state, fail fast without performing real HTTP calls.
- Expose the current circuit state via `GET /circuit/notify/status`.
- Do not use external Circuit Breaker libraries (e.g., `pybreaker`).

### Task 12: Change Detection & Synchronization
- Use the external ticket `updated_at` field to only update tickets that have changed.
- When tickets are deleted externally, apply a soft delete by setting `deleted_at` and exclude them from normal queries.
- Record field-level change history in a `ticket_history` collection so that ticket updates can be audited over time.

### Debug Task A: Multi-tenant Isolation
- The ticket listing API must never leak data across tenants.
- Review your `/tickets` implementation and make sure that results are always scoped to the requested `tenant_id`, even when additional filters (status, urgency, source, pagination) are applied.

### Debug Task B: Classification Quality
- The provided rule-based classification is intentionally simplistic and contains edge cases.
- Review and refine `ClassifyService` so that:
  - obviously critical tickets (e.g., strong refund / chargeback / legal threat signals) are treated with appropriate urgency,
  - sentiment and `requires_action` remain consistent with your rule set.

### Debug Task C: Memory Leak
- Repeated ingestion runs (e.g., 100+ times) cause memory usage to grow over time.
- Identify and fix the memory leak (for example, module-level caches or collections that are never cleaned up).

### Debug Task D: Race Condition
- Under concurrent `POST /ingest/run` calls for the same tenant, ingestion can sometimes run twice instead of being rejected.
- Find the check-then-act race condition and fix it using an atomic operation (for example, a single MongoDB atomic update).

### Debug Task E: Slow Stats Query
- When there are 10,000+ tickets, `GET /tenants/{tenant_id}/stats` can take more than 5 seconds.
- Use `explain()` to analyze the query plan and optimize indexes and/or the aggregation pipeline.
- Target a response time of roughly **â‰¤ 500ms** for 10,000 tickets in the provided `docker-compose` environment.

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.10+ (for local development)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/Youssef-Fawel/support-ticket-analytics-platform.git
cd support-ticket-analytics-platform
```

2. **Configure environment**
```bash
cp .env.example .env
```

3. **Start all services**
```bash
docker-compose up --build
```

The API will be available at `http://localhost:8000`

### Verify Installation

```bash
# Run all tests (should show 35/35 passing)
docker-compose exec app python -m pytest tests/ -v

# Check system health
curl http://localhost:8000/health
```

---

## ğŸ“š API Documentation

Once running, access interactive docs at:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Key Endpoints

#### Ingestion
```bash
# Start ticket ingestion for a tenant
POST /ingest/run?tenant_id=acme-corp

# Check ingestion status
GET /ingest/status?tenant_id=acme-corp

# View job progress
GET /ingest/progress/{job_id}

# Cancel running job
DELETE /ingest/{job_id}
```

#### Analytics
```bash
# Get tenant statistics
GET /tenants/{tenant_id}/stats

# Filter by date range
GET /tenants/{tenant_id}/stats?from_date=2024-01-01&to_date=2024-12-31
```

#### Tickets
```bash
# List tickets with filters
GET /tickets?tenant_id=acme-corp&status=open&urgency=high

# Get urgent tickets
GET /tickets/urgent?tenant_id=acme-corp

# View ticket details
GET /tickets/{ticket_id}?tenant_id=acme-corp

# Ticket change history
GET /tickets/{ticket_id}/history?tenant_id=acme-corp
```

#### Monitoring
```bash
# System health check
GET /health

# Circuit breaker status
GET /circuit/notify/status

# Reset circuit breaker (for testing)
POST /circuit/{name}/reset
```

---

## ğŸ§ª Testing

### Run Full Test Suite
```bash
docker-compose exec app python -m pytest tests/ -v
```

### Test Coverage
- âœ… Analytics aggregation
- âœ… Basic endpoints (health, ingestion, tickets)
- âœ… Circuit breaker (all state transitions)
- âœ… Concurrent ingestion (distributed locks)
- âœ… Data synchronization (change detection)
- âœ… Debug scenarios (memory leaks, race conditions)
- âœ… Deduplication & indexes
- âœ… Health monitoring & audit logs
- âœ… Hidden edge cases (tenant isolation)
- âœ… Notification retry logic
- âœ… Rate limiting (429 handling)

**Result: 35/35 tests passing (100%)**

---

## ğŸ›ï¸ Project Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py              # API endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py              # Configuration
â”‚   â”‚   â””â”€â”€ logging.py             # Logging setup
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ models.py              # Pydantic models
â”‚   â”‚   â”œâ”€â”€ mongo.py               # MongoDB connection
â”‚   â”‚   â””â”€â”€ indexes.py             # Database indexes
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ analytics_service.py   # Stats aggregation
â”‚   â”‚   â”œâ”€â”€ circuit_breaker.py     # Fault tolerance
â”‚   â”‚   â”œâ”€â”€ classify_service.py    # Ticket classification
â”‚   â”‚   â”œâ”€â”€ ingest_service.py      # Data ingestion
â”‚   â”‚   â”œâ”€â”€ lock_service.py        # Distributed locks
â”‚   â”‚   â”œâ”€â”€ notify_service.py      # Notifications
â”‚   â”‚   â”œâ”€â”€ rate_limiter.py        # Rate limiting
â”‚   â”‚   â””â”€â”€ sync_service.py        # Change detection
â”‚   â””â”€â”€ main.py                    # FastAPI app
â”œâ”€â”€ tests/                          # Comprehensive test suite
â”œâ”€â”€ mock_external_api/              # API simulator
â”œâ”€â”€ docker-compose.yml              # Container orchestration
â””â”€â”€ requirements.txt                # Python dependencies
```

---

## ğŸ”§ Configuration

### Environment Variables

```env
# MongoDB Configuration
MONGO_URL=mongodb://mongodb:27017
MONGO_DB=support_saas

# API Configuration
API_PORT=8000
EXTERNAL_API_URL=http://mock-external-api:9000

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60

# Circuit Breaker
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_WINDOW_SIZE=10
CIRCUIT_BREAKER_TIMEOUT=30
```

---

## ğŸ“Š Performance Benchmarks

| Metric | Target | Achieved |
|--------|--------|----------|
| Stats Query (10k tickets) | <500ms | âœ… ~350ms |
| Ingestion Rate | 60 req/min | âœ… 60 req/min |
| Concurrent Locks | No collisions | âœ… 409 on conflicts |
| Circuit Breaker Trips | At 5/10 failures | âœ… Working |
| Memory Stability | No leaks | âœ… Stable |

---

## ğŸ›¡ï¸ Production Readiness

### âœ… Implemented
- Event loop management (async/await)
- Connection pooling & resource cleanup
- Comprehensive error handling
- Structured logging
- Health checks
- Audit trails
- Test coverage (100%)
- Docker containerization

### ğŸ”œ Recommended Enhancements
- Kubernetes manifests
- Prometheus metrics
- Distributed tracing (OpenTelemetry)
- API rate limiting per tenant
- Redis caching layer
- ML-based classification

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Youssef Fawel**
- GitHub: [@Youssef-Fawel](https://github.com/Youssef-Fawel)

---

## ğŸ™ Acknowledgments

- FastAPI for the excellent async framework
- MongoDB for the flexible document database
- The Python async/await ecosystem

---

## ğŸ“ Support

For questions or issues, please [open an issue](https://github.com/Youssef-Fawel/support-ticket-analytics-platform/issues) on GitHub.
